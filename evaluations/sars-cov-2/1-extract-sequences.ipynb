{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b618adc-ca3a-46e9-948e-abdf1a99d2e4",
   "metadata": {},
   "source": [
    "# Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f33b46-2bb1-4258-aceb-edf4e2513d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('input/metadata.tsv.gz', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c04c9-b1a6-4f09-a72a-7d13f807e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd4418-8af0-4c46-a87d-8db9e712a962",
   "metadata": {},
   "source": [
    "## Look for duplicates in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17e022-cea6-43ca-8e47-cc5cc5e978d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_all = len(df)\n",
    "len_no_duplicates = df['strain'].agg('count')\n",
    "print(f'len_all={len_all} == len_no_duplicates={len_no_duplicates}: {len_all == len_no_duplicates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75751516-14f7-411c-9acc-7671500f1d64",
   "metadata": {},
   "source": [
    "# Extract sequences to separate files and prepare dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f637d2d-cb8f-4fe6-8cb8-80f34ab083bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "from os import mkdir\n",
    "import lzma\n",
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "total = len(df)\n",
    "\n",
    "in_file = Path('input/sequences.fasta.xz')\n",
    "out_dir = Path('input/split')\n",
    "\n",
    "if out_dir.exists():\n",
    "    shutil.rmtree(out_dir)\n",
    "\n",
    "if not out_dir.exists():\n",
    "    mkdir(out_dir)\n",
    "\n",
    "print_on = 2000\n",
    "\n",
    "time_before = time.time()\n",
    "count = 0\n",
    "input_file_data = []\n",
    "with lzma.open(in_file, 'tr') as ih:\n",
    "    for record in SeqIO.parse(ih, 'fasta'):\n",
    "        if count % print_on == 0:\n",
    "            percent = (count/total) * 100\n",
    "            print(f'{percent:0.1f}% ({count}/{total})')\n",
    "\n",
    "        cleaned_name = record.id.replace('/', '__')\n",
    "        out_file_path = (out_dir / f'{cleaned_name}.fasta.gz').absolute()\n",
    "        name = cleaned_name # record.id\n",
    "        input_file_data.append([name, str(out_file_path), pd.NA, pd.NA])\n",
    "        with gzip.open(out_file_path, \"wt\") as oh:\n",
    "            SeqIO.write(record, oh, \"fasta\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "input_file_df = pd.DataFrame(input_file_data, columns=['Sample', 'Assemblies', 'Reads1', 'Reads2'])\n",
    "time_after = time.time()\n",
    "print(f'Finished writing files to {out_dir}.')\n",
    "print(f'Took {(time_after - time_before)/60:0.1f} minutes')\n",
    "input_file_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad96282-b890-4746-8490-ed517498ad8e",
   "metadata": {},
   "source": [
    "# Save dataframe to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb15e5b-00d5-42ca-908c-a61d1ada9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from os import remove\n",
    "\n",
    "input_files_file = Path('input/input-files.tsv')\n",
    "\n",
    "if input_files_file.exists():\n",
    "    remove(input_files_file)\n",
    "    \n",
    "input_file_df.to_csv(input_files_file, sep='\\t', index=False)\n",
    "    \n",
    "print(f'Wrote input files to {input_files_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ef6c3-2e75-4dc0-a0a4-680cffc981ca",
   "metadata": {},
   "source": [
    "# ~Split dataframe into chunks~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946a162-aa6e-4ef7-90e9-02d31986bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# input_files_file_base_path = Path('input/input-list')\n",
    "\n",
    "# if input_files_file_base_path.exists():\n",
    "#     shutil.rmtree(input_files_file_base_path)\n",
    "    \n",
    "# if not input_files_file_base_path.exists():\n",
    "#     mkdir(input_files_file_base_path)\n",
    "    \n",
    "# max_samples_per_chunk = 100\n",
    "# number_chunks = int(math.ceil(len(input_file_df) / max_samples_per_chunk))\n",
    "\n",
    "# count = 0\n",
    "# for input_file_chunk_df in np.array_split(input_file_df, number_chunks):\n",
    "#     input_files_file = input_files_file_base_path / f'input_{count}.tsv'\n",
    "    \n",
    "#     input_file_chunk_df.to_csv(input_files_file, sep='\\t', index=False)\n",
    "#     count = count + 1\n",
    "    \n",
    "# print(f'Split list of files into {number_chunks} chunks files written to {input_files_file_base_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8d5bc-d37c-4e9b-9177-166742618245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
